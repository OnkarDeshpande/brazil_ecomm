{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 olist_customers_dataset.csv\n",
      "1 olist_geolocation_dataset.csv\n",
      "2 olist_orders_dataset.csv\n",
      "3 olist_order_items_dataset.csv\n",
      "4 olist_order_payments_dataset.csv\n",
      "5 olist_order_reviews_dataset.csv\n",
      "6 olist_products_dataset.csv\n",
      "7 olist_sellers_dataset.csv\n",
      "8 processed\n",
      "9 product_category_name_translation.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/'\n",
    "filenames = os.listdir(data_dir)\n",
    "for i, ele in enumerate(filenames):\n",
    "    print(i, ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files/ outputs of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      " 33%|███▎      | 1/3 [00:00<00:00,  3.98it/s]\r",
      "100%|██████████| 3/3 [00:00<00:00,  8.90it/s]\n",
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "100%|██████████| 3/3 [00:00<00:00, 34.09it/s]\n",
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "100%|██████████| 3/3 [00:00<00:00, 36.60it/s]\n",
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "100%|██████████| 3/3 [00:00<00:00, 73.18it/s]\n",
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "100%|██████████| 3/3 [00:00<00:00, 93.76it/s]\n"
     ]
    }
   ],
   "source": [
    "df_customers = utils.read_pickles('../data/processed/customers')\n",
    "df_orders = utils.read_pickles('../data/processed/orders')\n",
    "df_items = pd.read_csv(data_dir+filenames[3], parse_dates=['shipping_limit_date'])\n",
    "df_payments = utils.read_pickles('../data/processed/payments')\n",
    "df_products = utils.read_pickles('../data/processed/products')\n",
    "df_sellers = utils.read_pickles('../data/processed/sellers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping variables:\n",
    "* customer_unique_id and customer_id didn't add any value to the dataset\n",
    "* items price and frieght_value is removed to avoid **any information leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.drop(['customer_unique_id'], axis=1, inplace=True)\n",
    "df_orders.drop('customer_id', axis=1, inplace=True)\n",
    "df_items.drop(['price', 'freight_value'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining entities and specific datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: order_val\n",
       "  Entities:\n",
       "    orders [Rows: 99441, Columns: 7]\n",
       "    items [Rows: 112650, Columns: 6]\n",
       "    payments [Rows: 103886, Columns: 6]\n",
       "    customers [Rows: 99441, Columns: 5]\n",
       "    products [Rows: 32951, Columns: 9]\n",
       "    sellers [Rows: 3095, Columns: 4]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create entityset\n",
    "entity_set = ft.EntitySet(id = 'order_val')\n",
    "\n",
    "# order entity\n",
    "entity_set = entity_set.entity_from_dataframe(\n",
    "    entity_id='orders',\n",
    "    dataframe=df_orders,\n",
    "    index='order_id',\n",
    "    variable_types = {'order_status': ft.variable_types.Categorical}\n",
    ")\n",
    "\n",
    "# item entity\n",
    "entity_set = entity_set.entity_from_dataframe(\n",
    "    entity_id='items',\n",
    "    dataframe=df_items,\n",
    "    make_index=True,\n",
    "    index = 'item_id',\n",
    "    time_index = 'shipping_limit_date'\n",
    ")\n",
    "\n",
    "# payments entity\n",
    "entity_set = entity_set.entity_from_dataframe(\n",
    "    entity_id='payments',\n",
    "    dataframe=df_payments,\n",
    "    make_index=True,\n",
    "    index='payment_id',\n",
    "    variable_types = {'payment_type': ft.variable_types.Categorical}\n",
    ")\n",
    "\n",
    "# customers entity\n",
    "entity_set = entity_set.entity_from_dataframe(\n",
    "    entity_id='customers',\n",
    "    dataframe=df_customers,\n",
    "    index='customer_id',\n",
    "    variable_types = {'customer_city': ft.variable_types.Categorical,\n",
    "                     'customer_state': ft.variable_types.Categorical}\n",
    ")\n",
    "\n",
    "# product entity\n",
    "entity_set = entity_set.entity_from_dataframe(\n",
    "    entity_id='products',\n",
    "    dataframe=df_products,\n",
    "    index='product_id',\n",
    "    variable_types = {'product_category_name': ft.variable_types.Categorical}\n",
    ")\n",
    "\n",
    "# seller entity\n",
    "entity_set = entity_set.entity_from_dataframe(\n",
    "    entity_id='sellers',\n",
    "    dataframe=df_sellers,\n",
    "    index='seller_id',\n",
    "    variable_types = {'seller_city': ft.variable_types.Categorical,\n",
    "                     'seller_state': ft.variable_types.Categorical}\n",
    ")\n",
    "\n",
    "entity_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define relationship among datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: order_val\n",
       "  Entities:\n",
       "    orders [Rows: 99441, Columns: 7]\n",
       "    items [Rows: 112650, Columns: 6]\n",
       "    payments [Rows: 103886, Columns: 6]\n",
       "    customers [Rows: 99441, Columns: 5]\n",
       "    products [Rows: 32951, Columns: 9]\n",
       "    sellers [Rows: 3095, Columns: 4]\n",
       "  Relationships:\n",
       "    payments.order_id -> orders.order_id\n",
       "    items.order_id -> orders.order_id\n",
       "    customers.order_id -> orders.order_id\n",
       "    items.product_id -> products.product_id\n",
       "    items.seller_id -> sellers.seller_id"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the relationships (parents-->child) (parent have one id child may have multiple parent ids)\n",
    "relationship_orders_payments = ft.Relationship(entity_set['orders']['order_id'],\n",
    "                                               entity_set['payments']['order_id'])\n",
    "\n",
    "relationship_orders_items = ft.Relationship(entity_set['orders']['order_id'],\n",
    "                                            entity_set['items']['order_id'])\n",
    "\n",
    "relationship_orders_customers = ft.Relationship(entity_set['orders']['order_id'],\n",
    "                                            entity_set['customers']['order_id'])\n",
    "\n",
    "relationship_products_items = ft.Relationship(entity_set['products']['product_id'],\n",
    "                                              entity_set['items']['product_id']\n",
    "                                            )\n",
    "\n",
    "relationship_sellers_items = ft.Relationship(entity_set['sellers']['seller_id'],\n",
    "                                             entity_set['items']['seller_id']\n",
    "                                            )\n",
    "\n",
    "# Add the relationships to the entity set\n",
    "entity_set = entity_set.add_relationship(relationship_orders_payments)\n",
    "entity_set = entity_set.add_relationship(relationship_orders_items)\n",
    "entity_set = entity_set.add_relationship(relationship_orders_customers)\n",
    "entity_set = entity_set.add_relationship(relationship_products_items)\n",
    "entity_set = entity_set.add_relationship(relationship_sellers_items)\n",
    "\n",
    "# Check entity_set\n",
    "entity_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 294 features\n"
     ]
    }
   ],
   "source": [
    "transformation_feats = [ 'year', 'month', 'weekday', 'subtract']\n",
    "aggregate_feats = ['sum', 'mean', 'std', 'mode']\n",
    "feature_names = ft.dfs(entityset = entity_set,\n",
    "                          target_entity = \"orders\",\n",
    "                          trans_primitives = transformation_feats,\n",
    "                          agg_primitives = aggregate_feats,                 \n",
    "                          max_depth = 2,\n",
    "                          verbose = True,\n",
    "                          features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 294 features\n",
      "\n",
      "\r",
      "Elapsed: 00:00 | Remaining: ? | Progress:   0%|          | Calculated: 0/11 chunks\n",
      "\r",
      "Elapsed: 00:38 | Remaining: 06:27 | Progress:   9%|▉         | Calculated: 1/11 chunks\n",
      "\r",
      "Elapsed: 01:14 | Remaining: 05:33 | Progress:  18%|█▊        | Calculated: 2/11 chunks\n",
      "\r",
      "Elapsed: 01:49 | Remaining: 04:52 | Progress:  27%|██▋       | Calculated: 3/11 chunks\n",
      "\r",
      "Elapsed: 03:03 | Remaining: 05:21 | Progress:  36%|███▋      | Calculated: 4/11 chunks\n",
      "\r",
      "Elapsed: 04:15 | Remaining: 05:06 | Progress:  45%|████▌     | Calculated: 5/11 chunks\n",
      "\r",
      "Elapsed: 05:18 | Remaining: 04:25 | Progress:  55%|█████▍    | Calculated: 6/11 chunks\n",
      "\r",
      "Elapsed: 06:19 | Remaining: 03:36 | Progress:  64%|██████▎   | Calculated: 7/11 chunks\n",
      "\r",
      "Elapsed: 07:19 | Remaining: 02:44 | Progress:  73%|███████▎  | Calculated: 8/11 chunks\n",
      "\r",
      "Elapsed: 08:01 | Remaining: 01:47 | Progress:  82%|████████▏ | Calculated: 9/11 chunks\n",
      "\r",
      "Elapsed: 08:46 | Remaining: 00:52 | Progress:  91%|█████████ | Calculated: 10/11 chunks\n",
      "\r",
      "Elapsed: 08:47 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 11/11 chunks\n"
     ]
    }
   ],
   "source": [
    "df_features, feature_names = ft.dfs(entityset = entity_set,\n",
    "                                      target_entity = \"orders\",\n",
    "                                      trans_primitives = transformation_feats,\n",
    "                                      agg_primitives = aggregate_feats,                  \n",
    "                                      max_depth = 2,\n",
    "                                      verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eleminating features containing target information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = []\n",
    "for i,item in enumerate(df_features.columns):\n",
    "    if 'payment_value' in item:\n",
    "        drop_cols.append(item)\n",
    "\n",
    "# 8 SUM(payments.payment_value) is the target\n",
    "drop_cols.remove('SUM(payments.payment_value)')\n",
    "len(drop_cols)\n",
    "\n",
    "file = '../results/dropped_cols_ft6.2.txt'\n",
    "outfile = open(file, 'w')\n",
    "outfile.write(\"\\n\".join(drop_cols))\n",
    "\n",
    "df_features.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.rename(columns={'SUM(payments.payment_value)':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop cols with > 10% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = []\n",
    "rows = df_features.shape[0]\n",
    "for ele in df_features.columns:\n",
    "    if df_features[ele].isna().sum()/rows*100 > 10:\n",
    "        missing_cols.append(ele)\n",
    "        \n",
    "df_features.drop(missing_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]\n",
      "\r",
      "1it [00:00,  7.72it/s]\n",
      "\r",
      "2it [00:00,  7.74it/s]\n",
      "\r",
      "3it [00:00,  7.88it/s]\n"
     ]
    }
   ],
   "source": [
    "utils.to_pickles(df_features, '../data/processed/feature_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
